{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48875667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from smoothing import gaussian_smoothing_kernel\n",
    "from sharpening import sharpening_kernel\n",
    "from convolution import apply_convolution\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd019247",
   "metadata": {},
   "outputs": [],
   "source": [
    "lena = cv2.imread('./Lena.jpg', 1)\n",
    "\n",
    "cv2.imshow('Original Image', lena)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126637cf",
   "metadata": {},
   "source": [
    "## 2.a: Take an RGB image and apply convolution with each kernel, separately on each channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d0a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "lena_b = lena.copy()\n",
    "lena_b[:, :, 1] = 0\n",
    "lena_b[:, :, 2] = 0\n",
    "print(lena_b.shape)\n",
    "\n",
    "lena_g = lena.copy()\n",
    "lena_g[:, :, 0] = 0\n",
    "lena_g[:, :, 2] = 0\n",
    "print(lena_g.shape)\n",
    "\n",
    "lena_r = lena.copy()\n",
    "lena_r[:, :, 0] = 0\n",
    "lena_r[:, :, 1] = 0\n",
    "print(lena_r.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95451a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Lena Blue Channel\", lena_b)\n",
    "cv2.imshow(\"Lena Green Channel\", lena_g)\n",
    "cv2.imshow(\"Lena Red Channel\", lena_r)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae295b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512) (512, 512) (512, 512)\n"
     ]
    }
   ],
   "source": [
    "bc, gc, rc = cv2.split(lena)\n",
    "\n",
    "print(bc.shape, gc.shape, rc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975191ff",
   "metadata": {},
   "source": [
    "- Gaussian Smoothing Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd7f8eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00687486 0.02015726 0.02885054 0.02015726 0.00687486]\n",
      " [0.02015726 0.05910157 0.08459048 0.05910157 0.02015726]\n",
      " [0.02885054 0.08459048 0.12107208 0.08459048 0.02885054]\n",
      " [0.02015726 0.05910157 0.08459048 0.05910157 0.02015726]\n",
      " [0.00687486 0.02015726 0.02885054 0.02015726 0.00687486]]\n"
     ]
    }
   ],
   "source": [
    "smk = gaussian_smoothing_kernel(5, 1.67)\n",
    "\n",
    "print(smk)\n",
    "\n",
    "smooth_bc = apply_convolution(bc, smk)\n",
    "smooth_gc = apply_convolution(gc, smk)\n",
    "smooth_rc = apply_convolution(rc, smk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82696501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobel_1 = np.array(\n",
    "#     [\n",
    "#         [-1, 0, 1],\n",
    "#         [-1, 0, 1],\n",
    "#         [-1, 0, 1]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# sobel_2 = np.array(\n",
    "#     [\n",
    "#         [-1, -1, -1],\n",
    "#         [0, 0, 0],\n",
    "#         [1, 1, 1]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# apply_sobel_1 = apply_convolution(bc, sobel_1)\n",
    "# apply_sobel_2 = apply_convolution(bc, sobel_2)\n",
    "\n",
    "# sb1_cropped = apply_sobel_1[\"final\"]\n",
    "# sb2_cropped = apply_sobel_2[\"final\"]\n",
    "\n",
    "\n",
    "# gradient_magnitude = np.sqrt(sb1_cropped.astype(np.float64)**2 + sb2_cropped.astype(np.float64)**2)\n",
    "\n",
    "# # Normalize to 0-255 range for display\n",
    "# gradient_magnitude_norm = np.clip(gradient_magnitude, 0, 255).astype(np.uint8)\n",
    "# test = 255-gradient_magnitude_norm\n",
    "\n",
    "# cv2.imshow(\"Sobel 1\", sb1_cropped)\n",
    "# cv2.imshow(\"Sobel 2\", sb2_cropped)\n",
    "# cv2.imshow(\"Gradient Magnitude\", test)\n",
    "\n",
    "\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cb19d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_img_bc = smooth_bc[\"border_img\"]\n",
    "convo_bc = smooth_bc[\"raw_result\"]\n",
    "norm_bc = smooth_bc[\"normalized\"]\n",
    "norm_cropped_bc = smooth_bc[\"final\"]\n",
    "\n",
    "border_img_gc = smooth_gc[\"border_img\"]\n",
    "convo_gc = smooth_gc[\"raw_result\"]\n",
    "norm_gc = smooth_gc[\"normalized\"]\n",
    "norm_cropped_gc = smooth_gc[\"final\"]\n",
    "\n",
    "border_img_rc = smooth_rc[\"border_img\"]\n",
    "convo_rc = smooth_rc[\"raw_result\"]\n",
    "norm_rc = smooth_rc[\"normalized\"]\n",
    "norm_cropped_rc = smooth_rc[\"final\"]\n",
    "\n",
    "intermediate = cv2.merge((norm_cropped_bc, norm_cropped_gc, norm_cropped_rc))\n",
    "final = np.round(cv2.normalize(intermediate, None, 0, 255, cv2.NORM_MINMAX)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1e24686",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_only = np.zeros((norm_cropped_bc.shape[0], norm_cropped_bc.shape[1], 3), dtype=np.uint8)\n",
    "blue_only[:, :, 0] = 255 \n",
    "blue_only[:, :, 1] = 255-norm_cropped_bc\n",
    "blue_only[:, :, 2] = 255-norm_cropped_bc\n",
    "\n",
    "green_only = np.zeros((norm_cropped_bc.shape[0], norm_cropped_bc.shape[1], 3), dtype=np.uint8)\n",
    "green_only[:, :, 0] = 255-norm_cropped_gc\n",
    "green_only[:, :, 1] = 255\n",
    "green_only[:, :, 2] = 255-norm_cropped_gc\n",
    "\n",
    "red_only = np.zeros((norm_cropped_bc.shape[0], norm_cropped_bc.shape[1], 3), dtype=np.uint8)\n",
    "red_only[:, :, 0] = 255-norm_cropped_rc\n",
    "red_only[:, :, 1] = 255-norm_cropped_rc\n",
    "red_only[:, :, 2] = 255\n",
    "\n",
    "test = cv2.merge((norm_cropped_bc, norm_cropped_gc, norm_cropped_rc))\n",
    "\n",
    "cv2.imshow(\"Blue Channel Convolution Only\", blue_only)\n",
    "cv2.imshow(\"Green Channel Convolution Only\", green_only)\n",
    "cv2.imshow(\"Red Channel Convolution Only\", red_only)\n",
    "cv2.imshow(\"Final Merged Image\", test)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89b36598",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Blue Channel Border\", border_img_bc)\n",
    "cv2.imshow(\"Blue Channel Convo\", convo_bc)\n",
    "cv2.imshow(\"Blue Channel Norm\", norm_bc)\n",
    "cv2.imshow(\"Blue Channel Norm Cropped\", norm_cropped_bc)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04cd2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Green Channel Border\", border_img_gc)\n",
    "cv2.imshow(\"Green Channel Convo\", convo_gc)\n",
    "cv2.imshow(\"Green Channel Norm\", norm_gc)\n",
    "cv2.imshow(\"Green Channel Norm Cropped\", norm_cropped_gc)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6759cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Channel Border\", border_img_rc)\n",
    "cv2.imshow(\"Red Channel Convo\", convo_rc)\n",
    "cv2.imshow(\"Red Channel Norm\", norm_rc)\n",
    "cv2.imshow(\"Red Channel Norm Cropped\", norm_cropped_rc)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baa80c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Real\", lena)\n",
    "cv2.imshow(\"Final Merged Image\", final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a54b6d",
   "metadata": {},
   "source": [
    "- Gaussian Sharpening (LoG) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bcb6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc2, gc2, rc2 = cv2.split(lena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14e4eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shk = sharpening_kernel(7, 1.67)\n",
    "sh_bc = apply_convolution(bc2, shk)\n",
    "sh_gc = apply_convolution(gc2, shk)\n",
    "sh_rc = apply_convolution(rc2, shk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "352960bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_img_bc_2 = sh_bc[\"border_img\"]\n",
    "convo_bc_2 = sh_bc[\"raw_result\"]\n",
    "norm_bc_2 = sh_bc[\"normalized\"]\n",
    "norm_cropped_bc_2 = sh_bc[\"final\"]\n",
    "\n",
    "border_img_gc_2 = sh_gc[\"border_img\"]\n",
    "convo_gc_2 = sh_gc[\"raw_result\"]\n",
    "norm_gc_2 = sh_gc[\"normalized\"]\n",
    "norm_cropped_gc_2 = sh_gc[\"final\"]\n",
    "\n",
    "border_img_rc_2 = sh_rc[\"border_img\"]\n",
    "convo_rc_2 = sh_rc[\"raw_result\"]\n",
    "norm_rc_2 = sh_rc[\"normalized\"]\n",
    "norm_cropped_rc_2 = sh_rc[\"final\"]\n",
    "\n",
    "int2 = cv2.merge((norm_cropped_bc_2, norm_cropped_gc_2, norm_cropped_rc_2))\n",
    "final2 = np.round(cv2.normalize(int2, None, 0, 255, cv2.NORM_MINMAX)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cab80134",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_only_2 = np.zeros((norm_cropped_bc_2.shape[0], norm_cropped_bc_2.shape[1], 3), dtype=np.uint8)\n",
    "blue_only_2[:, :, 0] = norm_cropped_bc_2-255      \n",
    "blue_only_2[:, :, 1] =  0-norm_cropped_gc_2-255 \n",
    "blue_only_2[:, :, 2] = 0-norm_cropped_rc_2-255  \n",
    "\n",
    "green_only_2 = np.zeros((norm_cropped_gc_2.shape[0], norm_cropped_gc_2.shape[1], 3), dtype=np.uint8)\n",
    "green_only_2[:, :, 0] = 255-norm_cropped_gc_2 \n",
    "green_only_2[:, :, 1] = norm_cropped_gc_2        \n",
    "green_only_2[:, :, 2] = 255 -norm_cropped_gc_2  \n",
    "\n",
    "red_only_2 = np.zeros((norm_cropped_rc_2.shape[0], norm_cropped_rc_2.shape[1], 3), dtype=np.uint8)\n",
    "red_only_2[:, :, 0] = 255- norm_cropped_rc_2    \n",
    "red_only_2[:, :, 1] = 255- norm_cropped_rc_2   \n",
    "red_only_2[:, :, 2] = norm_cropped_rc_2         \n",
    "\n",
    "final_2 = cv2.merge((norm_cropped_bc_2, norm_cropped_gc_2, norm_cropped_rc_2))\n",
    "\n",
    "cv2.imshow(\"Blue Channel Convolution Only\", blue_only_2)\n",
    "cv2.imshow(\"Green Channel Convolution Only\", green_only_2)\n",
    "cv2.imshow(\"Red Channel Convolution Only\", red_only_2)\n",
    "cv2.imshow(\"Final Merged Image\", final_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e9281b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Blue Channel Border\", border_img_bc_2)\n",
    "cv2.imshow(\"Blue Channel Convo\", convo_bc_2)\n",
    "cv2.imshow(\"Blue Channel Norm\", norm_bc_2)\n",
    "cv2.imshow(\"Blue Channel Norm Cropped\", norm_cropped_bc_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66273b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Green Channel Border\", border_img_gc_2)\n",
    "cv2.imshow(\"Green Channel Convo\", convo_gc_2)\n",
    "cv2.imshow(\"Green Channel Norm\", norm_gc_2)\n",
    "cv2.imshow(\"Green Channel Norm Cropped\", norm_cropped_gc_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f035855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Channel Border\", border_img_rc_2)\n",
    "cv2.imshow(\"Red Channel Convo\", convo_rc_2)\n",
    "cv2.imshow(\"Red Channel Norm\", norm_rc_2)\n",
    "cv2.imshow(\"Red Channel Norm Cropped\", norm_cropped_rc_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97ae0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Real\", lena)\n",
    "cv2.imshow(\"Final Merged Image\", final2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877d3d2",
   "metadata": {},
   "source": [
    "## 2.b : Convert the RGB image to HSV mode and apply convolution with each kernel, separately on each channel of HSV space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e723ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_hsv = cv2.cvtColor(lena, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"Lena HSV\", lena_hsv)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee4f1e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "h, s, v = cv2.split(lena_hsv)\n",
    "\n",
    "print(h.shape)\n",
    "print(s.shape)\n",
    "print(v.shape)\n",
    "\n",
    "lena_h = lena_hsv.copy()\n",
    "lena_h[:, :, 1] = 0\n",
    "lena_h[:, :, 2] = 0\n",
    "\n",
    "lena_s = lena_hsv.copy()\n",
    "lena_s[:, :, 0] = 0\n",
    "lena_s[:, :, 2] = 0\n",
    "\n",
    "lena_v = lena_hsv.copy()\n",
    "lena_v[:, :, 0] = 0\n",
    "lena_v[:, :, 1] = 0\n",
    "\n",
    "cv2.imshow(\"Lena H Channel\", lena_h)\n",
    "cv2.imshow(\"Lena S Channel\", lena_s)\n",
    "cv2.imshow(\"Lena V Channel\", lena_v)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a8578",
   "metadata": {},
   "source": [
    "- Gaussian Smoothing Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4744aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_kernel = gaussian_smoothing_kernel(5, 1.67)\n",
    "\n",
    "h_sm_convo = apply_convolution(h, sm_kernel)\n",
    "s_sm_convo = apply_convolution(s, sm_kernel)\n",
    "v_sm_convo = apply_convolution(v, sm_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "162806b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_border = h_sm_convo[\"border_img\"]\n",
    "h_raw = h_sm_convo[\"raw_result\"]\n",
    "h_norm = h_sm_convo[\"normalized\"]\n",
    "h_final = h_sm_convo[\"final\"]\n",
    "\n",
    "s_border = s_sm_convo[\"border_img\"]\n",
    "s_raw = s_sm_convo[\"raw_result\"]\n",
    "s_norm = s_sm_convo[\"normalized\"]\n",
    "s_final = s_sm_convo[\"final\"]\n",
    "\n",
    "v_border = v_sm_convo[\"border_img\"]\n",
    "v_raw = v_sm_convo[\"raw_result\"]\n",
    "v_norm = v_sm_convo[\"normalized\"]\n",
    "v_final = v_sm_convo[\"final\"]\n",
    "\n",
    "\n",
    "int3 = cv2.merge((h_final, s_final, v_final))\n",
    "final_sm = np.round(cv2.normalize(int3, None, 0, 255, cv2.NORM_MINMAX)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e63e5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"H Border\", h_border)\n",
    "cv2.imshow(\"H Raw\", h_raw)\n",
    "cv2.imshow(\"H Norm\", h_norm)\n",
    "cv2.imshow(\"H Final\", h_final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fc00897",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"S Border\", s_border)\n",
    "cv2.imshow(\"S Raw\", s_raw)\n",
    "cv2.imshow(\"S Norm\", s_norm)\n",
    "cv2.imshow(\"S Final\", s_final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7cd00d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"V Border\", v_border)\n",
    "cv2.imshow(\"V Raw\", v_raw)\n",
    "cv2.imshow(\"V Norm\", v_norm)\n",
    "cv2.imshow(\"V Final\", v_final)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5216a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original HSV\", lena_hsv)\n",
    "cv2.imshow(\"Final SM\", final_sm)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f1265",
   "metadata": {},
   "source": [
    "- Sharpening Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3494ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_kernel = sharpening_kernel(7, 1.67)\n",
    "\n",
    "sh_h_convo = apply_convolution(h, sh_kernel)\n",
    "sh_s_convo = apply_convolution(s, sh_kernel)\n",
    "sh_v_convo = apply_convolution(v, sh_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5be5d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_border_sh = sh_h_convo[\"border_img\"]\n",
    "h_raw_sh = sh_h_convo[\"raw_result\"]\n",
    "h_norm_sh = sh_h_convo[\"normalized\"]\n",
    "h_final_sh = sh_h_convo[\"final\"]\n",
    "\n",
    "s_border_sh = sh_s_convo[\"border_img\"]\n",
    "s_raw_sh = sh_s_convo[\"raw_result\"]\n",
    "s_norm_sh = sh_s_convo[\"normalized\"]\n",
    "s_final_sh = sh_s_convo[\"final\"]\n",
    "\n",
    "v_border_sh = sh_v_convo[\"border_img\"]\n",
    "v_raw_sh = sh_v_convo[\"raw_result\"]\n",
    "v_norm_sh = sh_v_convo[\"normalized\"]\n",
    "v_final_sh = sh_v_convo[\"final\"]\n",
    "\n",
    "int4 = cv2.merge((h_final_sh, s_final_sh, v_final_sh))\n",
    "final_sh = np.round(cv2.normalize(int4, None, 0, 255, cv2.NORM_MINMAX)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30a23a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"H Border\", h_border_sh)\n",
    "cv2.imshow(\"H Raw\", h_raw_sh)\n",
    "cv2.imshow(\"H Norm\", h_norm_sh)\n",
    "cv2.imshow(\"H Final\", h_final_sh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa25f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"S Border\", s_border_sh)\n",
    "cv2.imshow(\"S Raw\", s_raw_sh)\n",
    "cv2.imshow(\"S Norm\", s_norm_sh)\n",
    "cv2.imshow(\"S Final\", s_final_sh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28eaa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"V Border\", v_border_sh)\n",
    "cv2.imshow(\"V Raw\", v_raw_sh)\n",
    "cv2.imshow(\"V Norm\", v_norm_sh)\n",
    "cv2.imshow(\"V Final\", v_final_sh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b63f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original HSV\", lena_hsv)\n",
    "cv2.imshow(\"Final SH\", final_sh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgenv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
